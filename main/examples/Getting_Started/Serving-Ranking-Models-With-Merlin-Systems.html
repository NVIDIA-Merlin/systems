<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Serving Ranking Models With Merlin Systems &mdash; Merlin Systems  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="API Documentation" href="../../api.html" />
    <link rel="prev" title="Merlin Systems Example Notebooks" href="../README.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Merlin Systems
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../README.html">Example Notebooks</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Serving Ranking Models With Merlin Systems</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Learning-objectives">Learning objectives</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Dataset">Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Tools">Tools</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Load-an-NVTabular-Workflow">Load an NVTabular Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Load-a-Tensorflow-Model">Load a Tensorflow Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Create-the-Ensemble-Graph">Create the Ensemble Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Export-Graph-as-Ensemble">Export Graph as Ensemble</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Verification-of-Ensemble-Artifacts">Verification of Ensemble Artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Starting-Triton-Server">Starting Triton Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Retrieving-Recommendations-from-Triton">Retrieving Recommendations from Triton</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../README.html#running-the-example-notebooks">Running the Example Notebooks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Merlin Systems</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../README.html">Merlin Systems Example Notebooks</a> &raquo;</li>
      <li>Serving Ranking Models With Merlin Systems</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright 2022 NVIDIA Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
</pre></div>
</div>
</div>
<p><img alt="589f98c1daa6487c84db8a891e4f690d" src="http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png" /></p>
<div class="section" id="Serving-Ranking-Models-With-Merlin-Systems">
<h1>Serving Ranking Models With Merlin Systems<a class="headerlink" href="#Serving-Ranking-Models-With-Merlin-Systems" title="Permalink to this headline"></a></h1>
<div class="section" id="Overview">
<h2>Overview<a class="headerlink" href="#Overview" title="Permalink to this headline"></a></h2>
<p>NVIDIA Merlin is an open source framework that accelerates and scales end-to-end recommender system pipelines. The Merlin framework is broken up into several sub components, these include: Merlin-Core, Merlin-Models, NVTabular and Merlin-Systems. Merlin Systems will be the focus of this example.</p>
<p>The purpose of the Merlin Systems library is to make it easy for Merlin users to quickly deploy their recommender systems from development to <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a>. We extended the same user-friendly API users are accustomed to in NVTabular and leveraged it to accommodate deploying your recommender system components to Triton.</p>
<p>There are some things we need ensure before we continue with this Notebook. Please ensure you have a working workflow and model stored in an accessible location. As previously mentioned, Merlin Systems will take the data preprocessing workflow defined in NVTabular and load that into Triton as a model. Subsequently it will do the same for the trained model. Lets take a closer look in the rest of this notebook at how Merlin systems makes deploying to Triton simple and effortless.</p>
<p><strong>Be sure to check the other components of the Merlin framework, they can help you</strong></p>
<div class="section" id="Learning-objectives">
<h3>Learning objectives<a class="headerlink" href="#Learning-objectives" title="Permalink to this headline"></a></h3>
<p>In this notebook, we learn how to deploy a NVTabular Workflow and a trained Tensorflow model from Merlin Models to Triton. - Load NVTabular Workflow - Load Pre-trained Merlin Models model - Create Ensemble Graph - Export Ensemble Graph - Run Tritonserver - Send Request to Tritonserver</p>
</div>
<div class="section" id="Dataset">
<h3>Dataset<a class="headerlink" href="#Dataset" title="Permalink to this headline"></a></h3>
<p>In this notebook, we will be leveraging the <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">Alibaba dataset</a>. It is important to note that the steps will take in this notebook are generalized and can be applied to any set of workflow and models. To see how the data is transformed please check the <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a> example for the Alibaba dataset. And to see how an Alibaba dataset trained model is created check the
<a class="reference external" href="https://github.com/NVIDIA-Merlin/models">merlin-models</a></p>
</div>
<div class="section" id="Tools">
<h3>Tools<a class="headerlink" href="#Tools" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>NVTabular</p></li>
<li><p>Merlin Models</p></li>
<li><p>Merlin Systems</p></li>
<li><p>Triton Inference Server</p></li>
</ul>
</div>
</div>
<div class="section" id="Load-an-NVTabular-Workflow">
<h2>Load an NVTabular Workflow<a class="headerlink" href="#Load-an-NVTabular-Workflow" title="Permalink to this headline"></a></h2>
<p>First, we load the <code class="docutils literal notranslate"><span class="pre">nvtabular.Workflow</span></code> that we created in with this <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/main/examples/04-Exporting-ranking-models.ipynb">example</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_GPU_ALLOCATOR&quot;</span><span class="p">]</span><span class="o">=</span><span class="s2">&quot;cuda_malloc_async&quot;</span>
<span class="kn">from</span> <span class="nn">nvtabular.workflow</span> <span class="kn">import</span> <span class="n">Workflow</span>

<span class="n">input_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INPUT_FOLDER&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>

<span class="n">workflow_stored_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s2">&quot;workflow&quot;</span><span class="p">)</span>

<span class="n">workflow</span> <span class="o">=</span> <span class="n">Workflow</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">workflow_stored_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/raid/workshared/nvtabular/nvtabular/workflow/workflow.py:373: UserWarning: Loading workflow generated with cudf version 21.10.00a+345.ge05bd4bf3c.dirty - but we are running cudf 21.12.02. This might cause issues
  warnings.warn(
</pre></div></div>
</div>
<p>After we load the workflow, we remove the label columns from it’s inputs. This removes all columns with the <code class="docutils literal notranslate"><span class="pre">TARGET</span></code> tag from the workflow. We do this because we need to set the workflow to only require the features needed to predict, not train, when creating an inference pipeline.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.schema.tags</span> <span class="kn">import</span> <span class="n">Tags</span>

<span class="n">label_columns</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">TARGET</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">remove_inputs</span><span class="p">(</span><span class="n">label_columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;nvtabular.workflow.workflow.Workflow at 0x7fa3240d10a0&gt;
</pre></div></div>
</div>
</div>
<div class="section" id="Load-a-Tensorflow-Model">
<h2>Load a Tensorflow Model<a class="headerlink" href="#Load-a-Tensorflow-Model" title="Permalink to this headline"></a></h2>
<p>After loading the workflow, we load the model. This model was trained with the output of the workflow from this <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/main/examples/04-Exporting-ranking-models.ipynb">example</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s2">&quot;dlrm&quot;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">tf_model_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-04-07 18:59:24.694276: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-07 18:59:26.773289: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0
2022-04-07 18:59:26.773451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18864 MB memory:  -&gt; device: 0, name: Quadro RTX 8000, pci bus id: 0000:15:00.0, compute capability: 7.5
2022-04-07 18:59:26.774073: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 1
2022-04-07 18:59:26.774136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 42858 MB memory:  -&gt; device: 1, name: Quadro RTX 8000, pci bus id: 0000:2d:00.0, compute capability: 7.5
</pre></div></div>
</div>
</div>
<div class="section" id="Create-the-Ensemble-Graph">
<h2>Create the Ensemble Graph<a class="headerlink" href="#Create-the-Ensemble-Graph" title="Permalink to this headline"></a></h2>
<p>Once we have both the model and the workflow loaded we can create the Ensemble Graph. This graph is created by the user, the goal is to illustrate the path of data through your full system. In this example we only serve a workflow with a model, but you can add other components that might be necessary to comply with business logic requirements.</p>
<p>For this example, because we have two components a model and a workflow we will require two operators. These operators, also known as Inference Operators, are meant to abstract away all the “hard parts” of loading a specific component (i.e. workflow or model) into tritonserver.</p>
<p>In the following code block we will leverage two Inference operators, the TransformWorkflow operator and the PredictTensorflow operator. The TransformWorkflow operator ensures the workflow is correctly saved and packaged with the required config, so tritonserver will know how to load it. The PredictTensorflow operator will do something similar with the model, loaded before.</p>
<p>Lets give it a try.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.dag.ops.workflow</span> <span class="kn">import</span> <span class="n">TransformWorkflow</span>
<span class="kn">from</span> <span class="nn">merlin.systems.dag.ops.tensorflow</span> <span class="kn">import</span> <span class="n">PredictTensorflow</span>

<span class="n">serving_operators</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">column_names</span> <span class="o">&gt;&gt;</span> <span class="n">TransformWorkflow</span><span class="p">(</span><span class="n">workflow</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">PredictTensorflow</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
</div>
<div class="section" id="Export-Graph-as-Ensemble">
<h2>Export Graph as Ensemble<a class="headerlink" href="#Export-Graph-as-Ensemble" title="Permalink to this headline"></a></h2>
<p>The last step is to create the ensemble artifacts that tritonserver can consume. To make these artifacts import the <code class="docutils literal notranslate"><span class="pre">Ensemble</span></code> class. It is responsible with interpreting the graph and exporting the correct files for tritonserver.</p>
<p>Below you will see that we create a ColumnSchema for the expected inputs to the workflow, which is a Schema.</p>
<p>When you are creating an <code class="docutils literal notranslate"><span class="pre">Ensemble</span></code> object you supply the graph and a schema representing the starting input of the graph. the inputs to the ensemble graph are the inputs to the first operator of your graph.</p>
<p>After you have created the <code class="docutils literal notranslate"><span class="pre">Ensemble</span></code> you export the graph, supplying an export path for the <code class="docutils literal notranslate"><span class="pre">Ensemble.export</span></code> function.</p>
<p>This returns an ensemble config which represents the entire inference pipeline and a list of node-specific configs.</p>
<p>Lets take a look below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[{&#39;name&#39;: &#39;user_id&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;item_id&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;item_category&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;item_shop&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;item_brand&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_shops&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_profile&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_group&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_gender&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_age&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_consumption_2&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_is_occupied&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_geography&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_intentions&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_brands&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}, {&#39;name&#39;: &#39;user_categories&#39;, &#39;tags&#39;: set(), &#39;properties&#39;: {}, &#39;dtype&#39;: dtype(&#39;O&#39;), &#39;is_list&#39;: False, &#39;is_ragged&#39;: False}]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.dag.ensemble</span> <span class="kn">import</span> <span class="n">Ensemble</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">ensemble</span> <span class="o">=</span> <span class="n">Ensemble</span><span class="p">(</span><span class="n">serving_operators</span><span class="p">,</span> <span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="p">)</span>

<span class="n">export_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s2">&quot;ensemble&quot;</span><span class="p">)</span>

<span class="n">ens_conf</span><span class="p">,</span> <span class="n">node_confs</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">export_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-04-07 18:59:31.098398: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, click/binary_classification_task/output_layer_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
INFO:tensorflow:Assets written to: /raid/data/ali/processed/ensemble/1_predicttensorflow/1/model.savedmodel/assets
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO:tensorflow:Assets written to: /raid/data/ali/processed/ensemble/1_predicttensorflow/1/model.savedmodel/assets
</pre></div></div>
</div>
</div>
<div class="section" id="Verification-of-Ensemble-Artifacts">
<h2>Verification of Ensemble Artifacts<a class="headerlink" href="#Verification-of-Ensemble-Artifacts" title="Permalink to this headline"></a></h2>
<p>Once the ensemble export has completed successfully, we can check the export path for the graph’s artifacts. You should see a file structure that represents a ordering number followed by an operator identifier(i.e. <code class="docutils literal notranslate"><span class="pre">1_transformworkflow</span></code>, <code class="docutils literal notranslate"><span class="pre">2_predicttensorflow</span></code>).</p>
<p>Inside each of those directories, the <code class="docutils literal notranslate"><span class="pre">export</span></code> method writes a <code class="docutils literal notranslate"><span class="pre">config.pbtxt</span></code> file and a directory with a number. The number indicates the version and begins at 1. The artifacts for each operator are found inside the version folder. These artifacts vary depending on the operator in question.</p>
<p>Please see the snapshot below for verification.</p>
<p><img alt="image.png" src="data:image/png;base64,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" /></p>
</div>
<div class="section" id="Starting-Triton-Server">
<h2>Starting Triton Server<a class="headerlink" href="#Starting-Triton-Server" title="Permalink to this headline"></a></h2>
<p>After we export the ensemble, we are ready to start the Triton Inference Server. First ensure it is installed in your environment otherwise find more install information here[link to triton build and install documentation]. Once installation is verified, you can start triton server by using the following command:</p>
<p><code class="docutils literal notranslate"><span class="pre">tritonserver</span> <span class="pre">--model-repository=/ensemble_export_path/</span> <span class="pre">--backend-config=tensorflow,version=2</span></code></p>
<p>For the <code class="docutils literal notranslate"><span class="pre">--model-repository</span></code> argument, specify the same value as the <code class="docutils literal notranslate"><span class="pre">export_path</span></code> that you specified previously in the <code class="docutils literal notranslate"><span class="pre">ensemble.export</span></code> method.</p>
</div>
<div class="section" id="Retrieving-Recommendations-from-Triton">
<h2>Retrieving Recommendations from Triton<a class="headerlink" href="#Retrieving-Recommendations-from-Triton" title="Permalink to this headline"></a></h2>
<p>Now that our tritonserver instance is running, we can send a request to it. This request is composed of values that correspond to the request schema created when exporting the ensemble graph.</p>
<p>We load original test data (<code class="docutils literal notranslate"><span class="pre">df_lib</span></code> is cudf if a GPU is available and pandas otherwise) as the <code class="docutils literal notranslate"><span class="pre">input_df</span></code> and we declare the <code class="docutils literal notranslate"><span class="pre">outputs</span></code> expected from the model. With both the <code class="docutils literal notranslate"><span class="pre">input_df</span></code> and <code class="docutils literal notranslate"><span class="pre">outputs</span></code> we can send an inference request to Triton, using <code class="docutils literal notranslate"><span class="pre">send_triton_request</span></code>. This inference response provided by Triton is parsed to return the expected predictions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.triton.utils</span> <span class="kn">import</span> <span class="n">send_triton_request</span>
<span class="kn">from</span> <span class="nn">merlin.core.dispatch</span> <span class="kn">import</span> <span class="n">get_lib</span>

<span class="n">df_lib</span> <span class="o">=</span> <span class="n">get_lib</span><span class="p">()</span>
<span class="n">original_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DATA_FOLDER&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>

<span class="c1"># read in data for request</span>
<span class="n">input_df</span> <span class="o">=</span> <span class="n">df_lib</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">original_data_path</span><span class="p">,</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="s2">&quot;test_0.parquet&quot;</span><span class="p">),</span> <span class="n">num_rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">column_names</span>
<span class="p">)</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">column_names</span>

<span class="n">parsed_response</span> <span class="o">=</span> <span class="n">send_triton_request</span><span class="p">(</span><span class="n">input_df</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">parsed_response</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;output_1&#39;: array([[0.04845615],
        [0.05534323],
        [0.00968392]], dtype=float32)}
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../README.html" class="btn btn-neutral float-left" title="Merlin Systems Example Notebooks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../api.html" class="btn btn-neutral float-right" title="API Documentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>